{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\praju\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LookupError: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\praju/nltk_data'\n",
      "    - 'c:\\\\Users\\\\praju\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\praju\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\praju\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\praju\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text = \"Hello, this is a test sentence.\"\n",
    "try:\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    print(\"Tokens:\", tokens)\n",
    "except LookupError as e:\n",
    "    print(\"LookupError:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2483246421.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    import nltknltk_data_path = nltk.data.find('tokenizers/punkt')\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltknltk_data_path = nltk.data.find('tokenizers/punkt')\n",
    "print(\"Punkt Tokenizer Path:\", nltk_data_path)\n",
    "punkt_path = os.path.dirname(nltk_data_path)\n",
    "print(\"Contents of punkt directory:\", os.listdir(punkt_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\praju\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text_data = \"\"\"\n",
    "My delight in Pride and Prejudice is so manifold that I \n",
    "hardly know how to begin telling it, but I am tempted first \n",
    "to try with my wonder at the constantly increasing fame of \n",
    "the author. Yet her fame seems the least thing in our love \n",
    "of her, our joy in her subtle and beautiful and ever adequate \n",
    "art. It is the dignity and sweetness and brightness of her \n",
    "nature which take us most, and our affection grows in honor \n",
    "of her as we think over the modest facts of her gentle life, \n",
    "which can be told in twenty lines, but never can be told often \n",
    "enough in their full significance. \n",
    "\n",
    "Unless daily sacrifice this side of martyrdom is a fault \n",
    "there is nothing to blame n the story of Jane Austenâ€™s life. \n",
    "Our other idols, literary idols, need veils in their temples \n",
    "where we like them to hide certain traits from us while we \n",
    "worship them, or at best receive from us a piety mixed with \n",
    "our pity; we cannot help knowing they were poor things, \n",
    "though divine. If our human frailties, our vices, our foibles, \n",
    "have a consecration in them it does not keep us from being \n",
    "ashamed, or at best, sorry for them. But this altogether \n",
    "admirable woman, good as she was great, we could offer \n",
    "praise without such reserve, when we joined last year in her \n",
    "apotheosis a century after her death. The defects of her quali- \n",
    "ties are as few as may be in our mortal conditioning, and \n",
    "they have the charm which she knew how to impart to the \n",
    "faults of her most endearing creations. But to talk of her \n",
    "so seems an offence against the restrained art which knew \n",
    "no excess, and it is like rather noisily boasting of the per- \n",
    "fectly ascertained loveliness of characters like Anne Elliott, \n",
    "Emma Woodhouse, Fanny Price, Catherine Morland, and \n",
    "above all Elizabeth Bennet, which each in its sort derived \n",
    "from the character of Jane Austen; for whether she knew it \n",
    "or not she always drew from herself, and gave the creatures \n",
    "she loved the loveliness of her own soul.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower() \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngrams(tokens, n):\n",
    "    return list(ngrams(tokens, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_model(ngrams):\n",
    "    model = defaultdict(list)\n",
    "    for ngram in ngrams:\n",
    "        prefix = ngram[:-1] \n",
    "        next_word = ngram[-1]\n",
    "        model[prefix].append(next_word)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, prefix):\n",
    "    prefix = tuple(prefix)\n",
    "    if prefix in model:\n",
    "        return model[prefix]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrect(input_word, model):\n",
    "    suggestions = []\n",
    "    for prefix in model:\n",
    "        if prefix[-1] == input_word:\n",
    "            suggestions.extend(model[prefix])\n",
    "    return list(set(suggestions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = preprocess_text(combined_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = create_ngrams(tokens, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_model = build_ngram_model(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next words: []\n"
     ]
    }
   ],
   "source": [
    "input_prefix = ['the', 'model']  # Example input\n",
    "predicted_words = predict_next_word(ngram_model, input_prefix)\n",
    "print(\"Predicted next words:\", predicted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrect suggestions: []\n"
     ]
    }
   ],
   "source": [
    "input_word = 'modle' \n",
    "suggestions = autocorrect(input_word, ngram_model)\n",
    "print(\"Autocorrect suggestions:\", suggestions)\n",
    "def test_ngram_model():\n",
    "    test_text = \"\"\"\n",
    "    The quick brown fox jumps over the lazy dog.\n",
    "    The dog barked back at the fox.\n",
    "    A quick movement of the enemy will jeopardize five gunboats.\n",
    "    The lazy dog didn't notice the fox.\n",
    "    \"\"\"\n",
    "    tokens = preprocess_text(test_text)\n",
    "    bigrams = create_ngrams(tokens, 2)\n",
    "    ngram_model = build_ngram_model(bigrams)\n",
    "    test_cases = [\n",
    "        (['the', 'lazy'], 'dog'),   # Expected prediction: 'dog'\n",
    "        (['the', 'quick'], 'brown'), # Expected prediction: 'brown'\n",
    "        (['the', 'fox'], 'jumps'),   # Expected prediction: 'jumps'\n",
    "        (['quick', 'movement'], 'of'), # Expected prediction: 'of'\n",
    "    ]\n",
    "    for prefix, expected in test_cases:\n",
    "        predicted = predict_next_word(ngram_model, prefix)\n",
    "        print(f\"Predicted for {prefix}: {predicted}, Expected: {expected}\")\n",
    "    input_word = 'dgo' \n",
    "    suggestions = autocorrect(input_word, ngram_model)\n",
    "    print(f\"Autocorrect suggestions for '{input_word}': {suggestions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted for ['the', 'lazy']: [], Expected: dog\n",
      "Predicted for ['the', 'quick']: [], Expected: brown\n",
      "Predicted for ['the', 'fox']: [], Expected: jumps\n",
      "Predicted for ['quick', 'movement']: [], Expected: of\n",
      "Autocorrect suggestions for 'dgo': []\n"
     ]
    }
   ],
   "source": [
    "test_ngram_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
